{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import pandas as pd\n",
    "\n",
    "numIn = 30 #how many time steps are we looking at\n",
    "numHidden = 3 #number of hidden layers\n",
    "numOut = 1 # len(apps) * 2 (on/off?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = buildNetwork(numIn, numHidden, numOut)\n",
    "ds = SupervisedDataSet(numIn,numOut)\n",
    "trainer = BackpropTrainer(net, ds)\n",
    "\n",
    "def train():\n",
    "    global net, ds, trainer\n",
    "    print trainer.train()\n",
    "    \n",
    "def toWindow(data):\n",
    "    for r in range(0, len(laptop)):\n",
    "        yield laptop['current'][r:r+numIn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0     0\n",
       "1     2\n",
       "2     2\n",
       "3     3\n",
       "4     0\n",
       "5     ...\n",
       "1    1     2\n",
       "2     2\n",
       "3     3\n",
       "4     0\n",
       "5     2\n",
       "6     ...\n",
       "2    2     2\n",
       "3     3\n",
       "4     0\n",
       "5     2\n",
       "6     0\n",
       "7     ...\n",
       "3    3     3\n",
       "4     0\n",
       "5     2\n",
       "6     0\n",
       "7     1\n",
       "8     ...\n",
       "4    4     0\n",
       "5     2\n",
       "6     0\n",
       "7     1\n",
       "8     0\n",
       "9     ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop = pd.read_csv('laptop.csv')\n",
    "laptop.head()\n",
    "laptop['time'] = laptop['time'].map( lambda t: float(t - laptop['time'][0]) * 0.001) #convert to milliseconds starting at 0\n",
    "laptop_inputs = pd.Series([li for li in toWindow(laptop) if len(li) == numIn])\n",
    "laptop_outputs = [0] * len(laptop_inputs)\n",
    "laptop_outputs[584:1138] = [1] * len(laptop_outputs[584:1138])\n",
    "laptop_outputs[4150:4242] = [-1] * len(laptop_outputs[4150:4242])\n",
    "laptop_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(laptop_outputs)):\n",
    "    ds.addSample(laptop_inputs[i], laptop_outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2b725e3e87b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#for i in range(epoch_number):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#    train()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainUntilConvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pybrain/supervised/trainers/backprop.pyc\u001b[0m in \u001b[0;36mtrainUntilConvergence\u001b[1;34m(self, dataset, maxEpochs, verbose, continueEpochs, validationProportion)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mvalidationErrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbestverr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[0mtrainingErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m             \u001b[0mvalidationErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestOnData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidationData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mvalidationErrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbestverr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pybrain/supervised/trainers/backprop.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffledSequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshuffledSequences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calcDerivs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0merrors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mponderation\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pybrain/supervised/trainers/backprop.pyc\u001b[0m in \u001b[0;36m_calcDerivs\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackActivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouterr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouterr\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m                 \u001b[0mponderation\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;31m# FIXME: the next line keeps arac from producing NaNs. I don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#epoch_number = 10\n",
    "#for i in range(epoch_number):\n",
    "#    train()\n",
    "trainer.trainUntilConvergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print len(laptop_inputs[0])\n",
    "training_ds = laptop_inputs.tolist()\n",
    "def test(training_ds):\n",
    "    global net\n",
    "    lst = []\n",
    "    for training in training_ds:\n",
    "        lst.append(net.activate(training))\n",
    "    return lst\n",
    "test_ans = pd.Series(test(training_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_ans = []\n",
    "for ans in test_ans:\n",
    "    if ans > 0.2:\n",
    "        norm_ans.append(1)\n",
    "    elif ans > 0:\n",
    "        norm_ans.append(0)\n",
    "    else:\n",
    "        norm_ans.append(-1)\n",
    "norm_ans = pd.Series(norm_ans)\n",
    "print float(sum([1 if norm_ans[i] == laptop_outputs[i] else 0 for i,_ in enumerate(norm_ans)])) / float(len(norm_ans))\n",
    "print float(sum([1 if 0 == laptop_outputs[i] else 0 for i,_ in enumerate(norm_ans)])) / float(len(norm_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in zip(norm_ans.tolist(), laptop_outputs):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
